{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf3ee53-d9c0-40fb-8d14-93e374f55a2b",
   "metadata": {},
   "source": [
    "# Polars & DuckDB: DataFrames and SQL For Python Without Pandas\n",
    "--------------------------\n",
    "\n",
    "__[1. Introduction](#first-bullet)__\n",
    "\n",
    "__[2. Getting Set Up On AWS with Docker](#second-bullet)__\n",
    "\n",
    "__[3. Intro To Polars DataFrames](#third-bullet)__\n",
    "\n",
    "__[4. DuckDB To The Rescue For SQL](#fourth-bullet)__\n",
    "\n",
    "__[5. Conclusions](#fifth)__\n",
    "\n",
    "\n",
    "## Introduction <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "------\n",
    "\n",
    "There are a plethora of dataframe alternatives to [Pandas](https://pandas.pydata.org/) due to its [limitations](https://insightsndata.com/what-are-the-limitations-of-pandas-35d462990c43), even the original author, Wes McKinney wrote a blog post about [10 Things I Hate About Pandas](https://wesmckinney.com/blog/apache-arrow-pandas-internals/). \n",
    "\n",
    "My biggest complaints to Pandas are:\n",
    "\n",
    "1. Memory usage\n",
    "2. Limited multi-core algorithms\n",
    "3. No ability to execute SQL statements (like [SparkSQL & DataFrame](https://spark.apache.org/sql/))\n",
    "4. No query planning/lazy-execution\n",
    "5. [NULL values only exist for floats not ints](https://pandas.pydata.org/docs/user_guide/integer_na.html) (this changed in Pandas 1.0+)\n",
    "6. Using [strings is inefficient](https://pandas.pydata.org/docs/user_guide/text.html) (this too changed in Pandas 1.0+\n",
    "    \n",
    "Many of these have been addressed by the [Pandas 2.0 release](https://pandas.pydata.org/docs/dev/whatsnew/v2.0.0.html). Over the years there has been many replacements for Pandas that have failed to gain traction in my opinion. And while there has been a steady march towards replacing the [NumPy](https://numpy.org/) backend with [Apache Arrow](https://arrow.apache.org/), I still feel the lack of SQL and overall API design is a major weakness.\n",
    "\n",
    "For context I have been using a [Apache Spark](https://spark.apache.org/) since 2017 and love it not just from a performance point of view, but just how well the API is designed. The syntax makes sense coming from a SQL users perspective. If I want to group by a column and count in SQL or on Spark DataFrame I get what I expect either way. For instance using this datas set from [NYC Open Data on Motor Vechicle Collisions](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95) in Pandas using a groupby-count expression I get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45782096-5f68-4198-8778-31f9badc7cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_date</th>\n",
       "      <th>crash_time</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "      <th>on_street_name</th>\n",
       "      <th>off_street_name</th>\n",
       "      <th>cross_street_name</th>\n",
       "      <th>number_of_persons_injured</th>\n",
       "      <th>...</th>\n",
       "      <th>contributing_factor_vehicle_2</th>\n",
       "      <th>contributing_factor_vehicle_3</th>\n",
       "      <th>contributing_factor_vehicle_4</th>\n",
       "      <th>contributing_factor_vehicle_5</th>\n",
       "      <th>collision_id</th>\n",
       "      <th>vehicle_type_code1</th>\n",
       "      <th>vehicle_type_code2</th>\n",
       "      <th>vehicle_type_code_3</th>\n",
       "      <th>vehicle_type_code_4</th>\n",
       "      <th>vehicle_type_code_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borough</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BRONX</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>48</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>106</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>92</td>\n",
       "      <td>247</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>247</td>\n",
       "      <td>242</td>\n",
       "      <td>157</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>153</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>56</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               crash_date  crash_time  zip_code  latitude  longitude   \n",
       "borough                                                                \n",
       "BRONX                 107         107       107       107        107  \\\n",
       "BROOKLYN              247         247       247       245        245   \n",
       "MANHATTAN              98          98        98        96         96   \n",
       "QUEENS                154         154       153       150        150   \n",
       "STATEN ISLAND          27          27        27        26         26   \n",
       "\n",
       "               location  on_street_name  off_street_name  cross_street_name   \n",
       "borough                                                                       \n",
       "BRONX               107              59               59                 48  \\\n",
       "BROOKLYN            245             155              155                 92   \n",
       "MANHATTAN            96              52               52                 46   \n",
       "QUEENS              150              98               98                 56   \n",
       "STATEN ISLAND        26              18               18                  9   \n",
       "\n",
       "               number_of_persons_injured  ...  contributing_factor_vehicle_2   \n",
       "borough                                   ...                                  \n",
       "BRONX                                107  ...                             81  \\\n",
       "BROOKLYN                             247  ...                            192   \n",
       "MANHATTAN                             98  ...                             65   \n",
       "QUEENS                               154  ...                            120   \n",
       "STATEN ISLAND                         27  ...                             21   \n",
       "\n",
       "               contributing_factor_vehicle_3  contributing_factor_vehicle_4   \n",
       "borough                                                                       \n",
       "BRONX                                      5                              0  \\\n",
       "BROOKLYN                                  24                              7   \n",
       "MANHATTAN                                  6                              1   \n",
       "QUEENS                                     9                              2   \n",
       "STATEN ISLAND                              2                              2   \n",
       "\n",
       "               contributing_factor_vehicle_5  collision_id   \n",
       "borough                                                      \n",
       "BRONX                                      0           107  \\\n",
       "BROOKLYN                                   2           247   \n",
       "MANHATTAN                                  1            98   \n",
       "QUEENS                                     0           154   \n",
       "STATEN ISLAND                              1            27   \n",
       "\n",
       "               vehicle_type_code1  vehicle_type_code2  vehicle_type_code_3   \n",
       "borough                                                                      \n",
       "BRONX                         106                  65                    4  \\\n",
       "BROOKLYN                      242                 157                   22   \n",
       "MANHATTAN                      96                  57                    5   \n",
       "QUEENS                        154                  97                    7   \n",
       "STATEN ISLAND                  27                  19                    2   \n",
       "\n",
       "               vehicle_type_code_4  vehicle_type_code_5  \n",
       "borough                                                  \n",
       "BRONX                            0                    0  \n",
       "BROOKLYN                         7                    2  \n",
       "MANHATTAN                        1                    0  \n",
       "QUEENS                           2                    0  \n",
       "STATEN ISLAND                    2                    1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd_df = pd.read_csv(\"https://data.cityofnewyork.us/resource/h9gi-nx95.csv\")\n",
    "pd_df.groupby(\"borough\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e5b421-e143-460a-9934-2dc02cdd480f",
   "metadata": {},
   "source": [
    "Notice this is the number of non nulls in every column. Not exactly what I wanted.\n",
    "\n",
    "To get what I want I have to use the syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8180247-2843-4666-9d49-1fba99d01ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "borough\n",
       "BRONX            107\n",
       "BROOKLYN         247\n",
       "MANHATTAN         98\n",
       "QUEENS           154\n",
       "STATEN ISLAND     27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.groupby(\"borough\").size() # or pd_df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ce36a-269b-4cc0-a57e-827002805619",
   "metadata": {},
   "source": [
    "But this returns a [Pandas Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html). It seems like a trivial difference, but counting duplicates in a column is easy in Spark because we can use method chaining, to the do the equivalent in Pandas I have to convert back to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d04cad-eaa3-4d84-b840-065b33ba2d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUEENS</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         borough  counts\n",
       "0          BRONX     107\n",
       "1       BROOKLYN     247\n",
       "2      MANHATTAN      98\n",
       "3         QUEENS     154\n",
       "4  STATEN ISLAND      27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.groupby(\"borough\").size().to_frame(\"counts\").reset_index().query(\"counts > 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d574f-1a1f-4cdd-b3f2-0386a08c0f3f",
   "metadata": {},
   "source": [
    "For years I have beening using Spark for large datasets, but for smaller ones sticking with Pandas. Recently though, I heard lots of hype about [Polars](https://www.pola.rs/) and [DuckDB](https://duckdb.org/) and decide to try them myself and was immediately impressed. \n",
    "\n",
    "In this blog post I go over my first interactions with both library's and call out things I like and dont like, but first let's get set up to run this notebook on an AWS EC2 instance using [Docker](https://www.docker.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b09c1-e210-48b4-b6bc-a9fdedf03c94",
   "metadata": {},
   "source": [
    "## Getting Set Up On AWS with Docker <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "\n",
    "I have mostly used [Google Cloud](https://cloud.google.com/) for my prior personal projects, but for this project I wanted to use [Amazon Web Services](https://aws.com/). The first thing I can do is create an [Elastic Comppute Cloud \n",
    "(EC2) Instance](https://aws.amazon.com/ec2/). I created this from the console on using a `t2.medium` by signign on to [aws.com](aws.com) clicking on ec2, scrolling down and clicking the orange `Launch instance`,\n",
    "\n",
    "![images/launch.png](images/launch.png)\n",
    "\n",
    "I had to make sure I created a `keypair` file called \"mikeskey.pem\" that I downloaded.\n",
    "\n",
    "![images/keypair.png](images/keypair.png)\n",
    "\n",
    "Notice that in the security group I allowed SSH traffice from \"Anywhere\". Once I launched it I could see the instance running and clicked on `Instance ID` as shown below:\n",
    "\n",
    "![images/instance.png](images/instance.png)\n",
    "\n",
    "and click on the pop up choice of `Connect`. This took me to another page where I got the command at the bottom to SSH onto my machine using the keypair:\n",
    "\n",
    "![images/connect.png](images/connect.png)\n",
    "\n",
    "I opened a terminal from my Macbook and ran:\n",
    "\n",
    "    ssh -i <path-to-key>/mikeskey.pem ec2-user@<dns-address>.compute-1.amazonaws.com\n",
    "\n",
    "Note that I didnt create a user name so it defaulted to `ec2-user`. \n",
    "\n",
    "Next I set up git ssh-keys so I could develop on the instance as described [here](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent) and cloned the repo. I then set up Docker as discussed [here](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create-container-image.html). I then build the image and called it `polars_nb` with the commands:\n",
    "\n",
    "    sudo docker build -t polars_nb . \n",
    "\n",
    "I could then start up the container from this image using port forwarding and loading the current directory as the volume:\n",
    "\n",
    "    sudo docker run -ip 8888:8888 -v `pwd`:/home/jovyan/ -t polars_nb\n",
    "\n",
    "This shows a link that I can copy and paste into my webbrowser, but at this stage it wont work. Since Jupyter is running on a remote EC2 server I need to set up [ssh-tunneling](https://linuxize.com/post/how-to-setup-ssh-tunneling/) as described [here](https://towardsdatascience.com/setting-up-and-using-jupyter-notebooks-on-aws-61a9648db6c5). I can do this using by opening a new terminal on my Mac and running the command:\n",
    "\n",
    "    ssh -i <path-to-key>/mikeskey.pem -L 8888:localhost:8888 ec2-user@<dns-address>.compute-1.amazonaws.com\n",
    "\n",
    "Now I can reload the notebook addres before and viola it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410616c2-1553-4c04-a181-e4f9922431b2",
   "metadata": {},
   "source": [
    "## Intro To Polars DataFrames <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "\n",
    "Now that we're set up with a notebook we can start to discuss [Polars](https://www.pola.rs/) dataframes. The Polars library is written in Rust with Python bindings. Polars uses multi-core processing making it fast and the authors smartly used [Apache Arrow](https://arrow.apache.org/) making it efficent for cross-language in-memory dataframes as there is no serialization between the Rust and Python.\n",
    "\n",
    "We can import polars and read in a dataset from [NY Open Data on Motor Vechicle Collisions](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95) using the [read_csv](https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.read_csv.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69f5f19a-7dfe-4df4-897a-637435677495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 29)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>crash_date</th><th>crash_time</th><th>borough</th><th>zip_code</th><th>latitude</th><th>longitude</th><th>location</th><th>on_street_name</th><th>off_street_name</th><th>cross_street_name</th><th>number_of_persons_injured</th><th>number_of_persons_killed</th><th>number_of_pedestrians_injured</th><th>number_of_pedestrians_killed</th><th>number_of_cyclist_injured</th><th>number_of_cyclist_killed</th><th>number_of_motorist_injured</th><th>number_of_motorist_killed</th><th>contributing_factor_vehicle_1</th><th>contributing_factor_vehicle_2</th><th>contributing_factor_vehicle_3</th><th>contributing_factor_vehicle_4</th><th>contributing_factor_vehicle_5</th><th>collision_id</th><th>vehicle_type_code1</th><th>vehicle_type_code2</th><th>vehicle_type_code_3</th><th>vehicle_type_code_4</th><th>vehicle_type_code_5</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;2021-09-11T00:…</td><td>&quot;2:39&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;WHITESTONE EXP…</td><td>&quot;20 AVENUE&quot;</td><td>null</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>&quot;Aggressive Dri…</td><td>&quot;Unspecified&quot;</td><td>null</td><td>null</td><td>null</td><td>4455765</td><td>&quot;Sedan&quot;</td><td>&quot;Sedan&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;2022-03-26T00:…</td><td>&quot;11:45&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;QUEENSBORO BRI…</td><td>null</td><td>null</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>&quot;Pavement Slipp…</td><td>null</td><td>null</td><td>null</td><td>null</td><td>4513547</td><td>&quot;Sedan&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 29)\n",
       "┌────────────┬────────────┬─────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ crash_date ┆ crash_time ┆ borough ┆ zip_code ┆ … ┆ vehicle_t ┆ vehicle_t ┆ vehicle_t ┆ vehicle_t │\n",
       "│ ---        ┆ ---        ┆ ---     ┆ ---      ┆   ┆ ype_code2 ┆ ype_code_ ┆ ype_code_ ┆ ype_code_ │\n",
       "│ str        ┆ str        ┆ str     ┆ i64      ┆   ┆ ---       ┆ 3         ┆ 4         ┆ 5         │\n",
       "│            ┆            ┆         ┆          ┆   ┆ str       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆            ┆         ┆          ┆   ┆           ┆ str       ┆ str       ┆ str       │\n",
       "╞════════════╪════════════╪═════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 2021-09-11 ┆ 2:39       ┆ null    ┆ null     ┆ … ┆ Sedan     ┆ null      ┆ null      ┆ null      │\n",
       "│ T00:00:00. ┆            ┆         ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 000        ┆            ┆         ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 2022-03-26 ┆ 11:45      ┆ null    ┆ null     ┆ … ┆ null      ┆ null      ┆ null      ┆ null      │\n",
       "│ T00:00:00. ┆            ┆         ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 000        ┆            ┆         ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴────────────┴─────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "df = pl.read_csv(\"https://data.cityofnewyork.us/resource/h9gi-nx95.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c1a685-c746-496c-adf8-8000054da881",
   "metadata": {},
   "source": [
    "The intial reading of CSVs is the same as Python and the [head](https://pola-rs.github.io/polars/py-polars/html/reference/dataframe/api/polars.DataFrame.head.html) dataframe method returns the top `n` rows as Pandas does. However, in addition I also get shape of the dataframe are shown as well as the datatypes othe columns. I can get the number of columns and datatypes of each column using the [schema](https://pola-rs.github.io/polars/py-polars/html/reference/dataframe/api/polars.DataFrame.schema.html) similar to Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dafbf2d6-58ac-47d9-982d-5e9fc58aa709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crash_date': Utf8,\n",
       " 'crash_time': Utf8,\n",
       " 'borough': Utf8,\n",
       " 'zip_code': Int64,\n",
       " 'latitude': Float64,\n",
       " 'longitude': Float64,\n",
       " 'location': Utf8,\n",
       " 'on_street_name': Utf8,\n",
       " 'off_street_name': Utf8,\n",
       " 'cross_street_name': Utf8,\n",
       " 'number_of_persons_injured': Int64,\n",
       " 'number_of_persons_killed': Int64,\n",
       " 'number_of_pedestrians_injured': Int64,\n",
       " 'number_of_pedestrians_killed': Int64,\n",
       " 'number_of_cyclist_injured': Int64,\n",
       " 'number_of_cyclist_killed': Int64,\n",
       " 'number_of_motorist_injured': Int64,\n",
       " 'number_of_motorist_killed': Int64,\n",
       " 'contributing_factor_vehicle_1': Utf8,\n",
       " 'contributing_factor_vehicle_2': Utf8,\n",
       " 'contributing_factor_vehicle_3': Utf8,\n",
       " 'contributing_factor_vehicle_4': Utf8,\n",
       " 'contributing_factor_vehicle_5': Utf8,\n",
       " 'collision_id': Int64,\n",
       " 'vehicle_type_code1': Utf8,\n",
       " 'vehicle_type_code2': Utf8,\n",
       " 'vehicle_type_code_3': Utf8,\n",
       " 'vehicle_type_code_4': Utf8,\n",
       " 'vehicle_type_code_5': Utf8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e78ae-d0db-461d-a3f2-66cc25c827f9",
   "metadata": {},
   "source": [
    "We can see that the datatypes of Polars are built on top of [Arrow's datatypes](https://arrow.apache.org/docs/python/api/datatypes.html) which is great.\n",
    "\n",
    "The first command I tried with Polars was looking for duplicates in the dataframe. I found I could do this with the syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a16fb05-51e1-4697-a72e-e96eefd28c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>collision_id</th><th>count</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 2)\n",
       "┌──────────────┬───────┐\n",
       "│ collision_id ┆ count │\n",
       "│ ---          ┆ ---   │\n",
       "│ i64          ┆ u32   │\n",
       "╞══════════════╪═══════╡\n",
       "└──────────────┴───────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = (df.groupby(\"collision_id\")\n",
    "           .count()\n",
    "           .filter(pl.col(\"count\") > 1))\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b1f2c-95ec-4aa8-9330-a259c7647716",
   "metadata": {},
   "source": [
    "Right away from the syntax I was onboard. Then I saw statements return a dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e7739fc-bcd7-469e-8d14-3f4dbf864bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.dataframe.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0338c796-9448-4fe0-9f69-5f7fc2a42bfa",
   "metadata": {},
   "source": [
    "This is exactly what I want! I dont want a series! You can even print the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11fa12df-247f-4472-bc65-45a74469a5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (0, 2)\n",
      "┌──────────────┬───────┐\n",
      "│ collision_id ┆ count │\n",
      "│ ---          ┆ ---   │\n",
      "│ i64          ┆ u32   │\n",
      "╞══════════════╪═══════╡\n",
      "└──────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96696e39-9631-4a80-b915-e9757e730818",
   "metadata": {},
   "source": [
    "This turns out to be helpful when you have lazy execution (which I'll go over later). The next thing I tried was to access the column of the dataframe by using the got operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c46a46-da02-4293-b10c-ca233b6f71a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'crash_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrash_date\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'crash_date'"
     ]
    }
   ],
   "source": [
    "df.crash_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c4941-d1ec-4e65-8a8a-4810f61ef297",
   "metadata": {},
   "source": [
    "I was actually happy to see this as to me, a column in a dataframe should not be accessed this way. Instead we can access it like a dictionary's key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "437add7e-f16c-46f4-b6df-f1c98e00ab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"crash_date\"].is_null().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe9004-55bf-4405-a04c-4a36c7b3051f",
   "metadata": {},
   "source": [
    "The crash dates are strings that I wante to convert to datetime type. I can see the format of the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1690a44-9e14-4164-92ae-6d88010b80be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-09-11T00:00:00.000'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['crash_date'][0] # the .loc method doesnt exist!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a087e12-9cc1-44ee-afb8-865769770ee7",
   "metadata": {},
   "source": [
    "Now I can extract the year-month-day from the string and assign that value a new column name called `crash_date_str`. Note the synatx to create a new column is to use a [with_columns](https://pola-rs.github.io/polars/py-polars/html/reference/dataframe/api/polars.DataFrame.with_columns.html) method (similar to [withColumn](https://sparkbyexamples.com/pyspark/pyspark-withcolumn/)) and I have to use the [col](https://pola-rs.github.io/polars/py-polars/html/reference/expressions/api/polars.col.html) function similar to Spark! I can get the first 10 lengths using str methods similar to Pandas. Finally, I rename the new column `crash_data_str` using the [alias](https://pola-rs.github.io/polars/py-polars/html/reference/expressions/api/polars.Expr.alias.html) function like Spark! The default is to call the new column name the same as the old column. The next query you can see below is to strip the timestamp from the `crash_date_str` column and then convert it to a Polars datetime object and rename it `crash_date`. The results are below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0f3b0ae-9f70-4504-a74b-f2823ac1bd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 30)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>crash_date</th><th>crash_time</th><th>borough</th><th>zip_code</th><th>latitude</th><th>longitude</th><th>location</th><th>on_street_name</th><th>off_street_name</th><th>cross_street_name</th><th>number_of_persons_injured</th><th>number_of_persons_killed</th><th>number_of_pedestrians_injured</th><th>number_of_pedestrians_killed</th><th>number_of_cyclist_injured</th><th>number_of_cyclist_killed</th><th>number_of_motorist_injured</th><th>number_of_motorist_killed</th><th>contributing_factor_vehicle_1</th><th>contributing_factor_vehicle_2</th><th>contributing_factor_vehicle_3</th><th>contributing_factor_vehicle_4</th><th>contributing_factor_vehicle_5</th><th>collision_id</th><th>vehicle_type_code1</th><th>vehicle_type_code2</th><th>vehicle_type_code_3</th><th>vehicle_type_code_4</th><th>vehicle_type_code_5</th><th>crash_date_str</th></tr><tr><td>datetime[μs]</td><td>str</td><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2021-09-11 00:00:00</td><td>&quot;2:39&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;WHITESTONE EXP…</td><td>&quot;20 AVENUE&quot;</td><td>null</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>&quot;Aggressive Dri…</td><td>&quot;Unspecified&quot;</td><td>null</td><td>null</td><td>null</td><td>4455765</td><td>&quot;Sedan&quot;</td><td>&quot;Sedan&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;2021-09-11&quot;</td></tr><tr><td>2022-03-26 00:00:00</td><td>&quot;11:45&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;QUEENSBORO BRI…</td><td>null</td><td>null</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>&quot;Pavement Slipp…</td><td>null</td><td>null</td><td>null</td><td>null</td><td>4513547</td><td>&quot;Sedan&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;2022-03-26&quot;</td></tr><tr><td>2022-06-29 00:00:00</td><td>&quot;6:55&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;THROGS NECK BR…</td><td>null</td><td>null</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&quot;Following Too …</td><td>&quot;Unspecified&quot;</td><td>null</td><td>null</td><td>null</td><td>4541903</td><td>&quot;Sedan&quot;</td><td>&quot;Pick-up Truck&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;2022-06-29&quot;</td></tr><tr><td>2021-09-11 00:00:00</td><td>&quot;9:35&quot;</td><td>&quot;BROOKLYN&quot;</td><td>11208</td><td>40.667202</td><td>-73.8665</td><td>&quot;\n",
       ",  \n",
       "(40.66720…</td><td>null</td><td>null</td><td>&quot;1211      LORI…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&quot;Unspecified&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>4456314</td><td>&quot;Sedan&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;2021-09-11&quot;</td></tr><tr><td>2021-12-14 00:00:00</td><td>&quot;8:13&quot;</td><td>&quot;BROOKLYN&quot;</td><td>11233</td><td>40.683304</td><td>-73.917274</td><td>&quot;\n",
       ",  \n",
       "(40.68330…</td><td>&quot;SARATOGA AVENU…</td><td>&quot;DECATUR STREET…</td><td>null</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>4486609</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;2021-12-14&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 30)\n",
       "┌────────────┬───────────┬──────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ crash_date ┆ crash_tim ┆ borough  ┆ zip_code ┆ … ┆ vehicle_t ┆ vehicle_t ┆ vehicle_t ┆ crash_dat │\n",
       "│ ---        ┆ e         ┆ ---      ┆ ---      ┆   ┆ ype_code_ ┆ ype_code_ ┆ ype_code_ ┆ e_str     │\n",
       "│ datetime[μ ┆ ---       ┆ str      ┆ i64      ┆   ┆ 3         ┆ 4         ┆ 5         ┆ ---       │\n",
       "│ s]         ┆ str       ┆          ┆          ┆   ┆ ---       ┆ ---       ┆ ---       ┆ str       │\n",
       "│            ┆           ┆          ┆          ┆   ┆ str       ┆ str       ┆ str       ┆           │\n",
       "╞════════════╪═══════════╪══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 2021-09-11 ┆ 2:39      ┆ null     ┆ null     ┆ … ┆ null      ┆ null      ┆ null      ┆ 2021-09-1 │\n",
       "│ 00:00:00   ┆           ┆          ┆          ┆   ┆           ┆           ┆           ┆ 1         │\n",
       "│ 2022-03-26 ┆ 11:45     ┆ null     ┆ null     ┆ … ┆ null      ┆ null      ┆ null      ┆ 2022-03-2 │\n",
       "│ 00:00:00   ┆           ┆          ┆          ┆   ┆           ┆           ┆           ┆ 6         │\n",
       "│ 2022-06-29 ┆ 6:55      ┆ null     ┆ null     ┆ … ┆ null      ┆ null      ┆ null      ┆ 2022-06-2 │\n",
       "│ 00:00:00   ┆           ┆          ┆          ┆   ┆           ┆           ┆           ┆ 9         │\n",
       "│ 2021-09-11 ┆ 9:35      ┆ BROOKLYN ┆ 11208    ┆ … ┆ null      ┆ null      ┆ null      ┆ 2021-09-1 │\n",
       "│ 00:00:00   ┆           ┆          ┆          ┆   ┆           ┆           ┆           ┆ 1         │\n",
       "│ 2021-12-14 ┆ 8:13      ┆ BROOKLYN ┆ 11233    ┆ … ┆ null      ┆ null      ┆ null      ┆ 2021-12-1 │\n",
       "│ 00:00:00   ┆           ┆          ┆          ┆   ┆           ┆           ┆           ┆ 4         │\n",
       "└────────────┴───────────┴──────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.with_columns(\n",
    "            pl.col(\"crash_date\").str.slice(0, length=10).alias(\"crash_date_str\")\n",
    "      ).with_columns(\n",
    "            pl.col(\"crash_date_str\").str.strptime(\n",
    "                pl.Datetime, \"%Y-%m-%d\", strict=False).alias(\"crash_date\")\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08663530-c746-4e42-860f-3453da3b9646",
   "metadata": {},
   "source": [
    "Notice the [col](https://pola-rs.github.io/polars/py-polars/html/reference/expressions/api/polars.col.html) function in Polars lets me access derived columns that are not in the original dataframe. In Pandas to the same operations I would have to use a lambda function within an assign function:\n",
    "\n",
    "    df.assign(crash_date=lambda: df[\"crash_date_str\"].str.strptime(...))\n",
    "\n",
    "I can see the number of crashes in each borough of NYC with the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18b045c9-1ec2-4ebd-86fc-7fd13d700e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>borough</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;BROOKLYN&quot;</td><td>247</td></tr><tr><td>&quot;MANHATTAN&quot;</td><td>98</td></tr><tr><td>null</td><td>367</td></tr><tr><td>&quot;QUEENS&quot;</td><td>154</td></tr><tr><td>&quot;STATEN ISLAND&quot;</td><td>27</td></tr><tr><td>&quot;BRONX&quot;</td><td>107</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 2)\n",
       "┌───────────────┬───────┐\n",
       "│ borough       ┆ count │\n",
       "│ ---           ┆ ---   │\n",
       "│ str           ┆ u32   │\n",
       "╞═══════════════╪═══════╡\n",
       "│ BROOKLYN      ┆ 247   │\n",
       "│ MANHATTAN     ┆ 98    │\n",
       "│ null          ┆ 367   │\n",
       "│ QUEENS        ┆ 154   │\n",
       "│ STATEN ISLAND ┆ 27    │\n",
       "│ BRONX         ┆ 107   │\n",
       "└───────────────┴───────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"borough\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1aa9b1-e3d6-484e-90db-8742d5cd5fdb",
   "metadata": {},
   "source": [
    "There is a borough value of NULL. I can filture this out with the commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1682237a-b41e-4042-95e5-a4a5922b9088",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_df = df.filter(pl.col(\"borough\").is_not_null())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f984a-b86b-4f63-98a0-cde2fe62b4cf",
   "metadata": {},
   "source": [
    "Now I can get just the unique values of non-null boroughs with the query: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e2dd6e6-8e72-430c-8160-cedbae02ca3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>borough</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;BRONX&quot;</td></tr><tr><td>&quot;BROOKLYN&quot;</td></tr><tr><td>&quot;QUEENS&quot;</td></tr><tr><td>&quot;MANHATTAN&quot;</td></tr><tr><td>&quot;STATEN ISLAND&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌───────────────┐\n",
       "│ borough       │\n",
       "│ ---           │\n",
       "│ str           │\n",
       "╞═══════════════╡\n",
       "│ BRONX         │\n",
       "│ BROOKLYN      │\n",
       "│ QUEENS        │\n",
       "│ MANHATTAN     │\n",
       "│ STATEN ISLAND │\n",
       "└───────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(pl.col(\"borough\").is_not_null()).select(\"borough\").unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abb4cc8-734d-4f79-afa6-e0626be6cc59",
   "metadata": {},
   "source": [
    "Notice that I can use the [select](https://pola-rs.github.io/polars/py-polars/html/reference/dataframe/api/polars.DataFrame.select.html) method in Polars. This is actually pretty powerful, as I can select columns and run queries on them similar to [selectEpr](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.DataFrame.selectExpr.html) in Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cdde422-3f47-4c09-abf4-9ddfcb790313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>borough</th><th>number_of_persons_injured_plus1</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;BROOKLYN&quot;</td><td>1</td></tr><tr><td>&quot;BROOKLYN&quot;</td><td>1</td></tr><tr><td>&quot;BRONX&quot;</td><td>3</td></tr><tr><td>&quot;BROOKLYN&quot;</td><td>1</td></tr><tr><td>&quot;MANHATTAN&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌───────────┬─────────────────────────────────┐\n",
       "│ borough   ┆ number_of_persons_injured_plus1 │\n",
       "│ ---       ┆ ---                             │\n",
       "│ str       ┆ i64                             │\n",
       "╞═══════════╪═════════════════════════════════╡\n",
       "│ BROOKLYN  ┆ 1                               │\n",
       "│ BROOKLYN  ┆ 1                               │\n",
       "│ BRONX     ┆ 3                               │\n",
       "│ BROOKLYN  ┆ 1                               │\n",
       "│ MANHATTAN ┆ 1                               │\n",
       "└───────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.filter(pl.col(\"borough\").is_not_null())\n",
    "   .select([\n",
    "       \"borough\", \n",
    "       (pl.col(\"number_of_persons_injured\")  + 1).alias(\"number_of_persons_injured_plus1\")\n",
    "    ]).head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcd93c8-8926-4803-9d81-220d104bfa63",
   "metadata": {},
   "source": [
    "Doing the above in Pandas is a little convoluted using in one command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "180a8b21-524a-400b-8e4b-83bb7f1c030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "      <th>number_of_persons_injured_plus1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     borough  number_of_persons_injured_plus1\n",
       "3   BROOKLYN                                1\n",
       "4   BROOKLYN                                1\n",
       "7      BRONX                                3\n",
       "8   BROOKLYN                                1\n",
       "9  MANHATTAN                                1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd_df[~pd_df[\"borough\"].isnull()]\n",
    "      .assign(number_of_persons_injured_plus1=pd_df[\"number_of_persons_injured\"] + 1)\n",
    "      [[\"borough\", \"number_of_persons_injured_plus1\"]]\n",
    "      .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54d249-1291-4287-a10b-be714e28cf92",
   "metadata": {},
   "source": [
    "To me, the Polars query is so much easier to read. And its actually more efficient. The Pandas dataframe transforms the whole dataset, then subsets the columns to return just two. On the other hand Polars subsets the columns first and then add transform just those two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f1e0c-7e90-49ea-b427-39890f3d5f4b",
   "metadata": {},
   "source": [
    "Now I can create a dataframe the exact same way as in Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcf1932d-95f7-4efc-8681-acafb3d2e1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌───────────────┬────────────┬───────┐\n",
      "│ borough       ┆ population ┆ area  │\n",
      "│ ---           ┆ ---        ┆ ---   │\n",
      "│ str           ┆ i64        ┆ f64   │\n",
      "╞═══════════════╪════════════╪═══════╡\n",
      "│ BROOKLYN      ┆ 2590516    ┆ 179.7 │\n",
      "│ BRONX         ┆ 1379946    ┆ 109.2 │\n",
      "│ MANHATTAN     ┆ 1596273    ┆ 58.68 │\n",
      "│ STATEN ISLAND ┆ 2278029    ┆ 281.6 │\n",
      "│ QUEENS        ┆ 378977     ┆ 149.0 │\n",
      "└───────────────┴────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "borough_df = pl.DataFrame({\n",
    "                \"borough\": [\"BROOKLYN\", \"BRONX\", \"MANHATTAN\", \"STATEN ISLAND\", \"QUEENS\"],\n",
    "                \"population\": [2590516, 1379946, 1596273, 2278029, 378977],\n",
    "                \"area\":[179.7, 109.2, 58.68, 281.6, 149.0]\n",
    "})\n",
    "\n",
    "print(borough_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f30190-9190-4748-8ab3-33e7c06acb3d",
   "metadata": {},
   "source": [
    "Now lets go over a more complicated query, I can join the borough dataframe above to the dataframe we have to get the total number of injuries per borough then join that to the borough dataframe to get the injuries by population and sort them by borough name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06db93ed-9664-46aa-bae2-c6d05e0aeff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>borough</th><th>injuries_per_population</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;BRONX&quot;</td><td>0.000033</td></tr><tr><td>&quot;BROOKLYN&quot;</td><td>0.000045</td></tr><tr><td>&quot;MANHATTAN&quot;</td><td>0.000025</td></tr><tr><td>&quot;QUEENS&quot;</td><td>0.000193</td></tr><tr><td>&quot;STATEN ISLAND&quot;</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌───────────────┬─────────────────────────┐\n",
       "│ borough       ┆ injuries_per_population │\n",
       "│ ---           ┆ ---                     │\n",
       "│ str           ┆ f64                     │\n",
       "╞═══════════════╪═════════════════════════╡\n",
       "│ BRONX         ┆ 0.000033                │\n",
       "│ BROOKLYN      ┆ 0.000045                │\n",
       "│ MANHATTAN     ┆ 0.000025                │\n",
       "│ QUEENS        ┆ 0.000193                │\n",
       "│ STATEN ISLAND ┆ 0.000007                │\n",
       "└───────────────┴─────────────────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.filter(pl.col(\"borough\").is_not_null())\n",
    "   .select([\"borough\", \"number_of_persons_injured\"])\n",
    "   .groupby(\"borough\")\n",
    "   .sum()\n",
    "   .join(borough_df, on=[\"borough\"])\n",
    "   .select([\n",
    "       \"borough\", \n",
    "       (pl.col(\"number_of_persons_injured\") / pl.col(\"population\")).alias(\"injuries_per_population\")\n",
    "   ])\n",
    "   .sort(pl.col(\"borough\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e99dd45-37d7-48bd-a7f4-5e6a8c03fb5f",
   "metadata": {},
   "source": [
    "This is really cool as its very easy to use method chaining and reads pretty close to SQL! Doing the same thign in the Pandas API would be an awkward mess.\n",
    "\n",
    "Which brings me to something that was super exciting to see in Polars: [sqlcontext](https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.SQLContext.execute.html). SQLContext in Polars can be used to create a table to run SQL on from a Polars dataframe as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57aa37a5-cff8-405f-a1be-b80c52cd73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = pl.SQLContext(crashes=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33954ddd-8562-4c4e-a6cc-a1b5c4fa2ba3",
   "metadata": {},
   "source": [
    "Now I can get the sum of every crash in each borough per day and execute it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "253abd24-8ba7-4caf-9242-cbf192da5890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>borough</th><th>day</th><th>number_of_persons_injured</th></tr><tr><td>str</td><td>datetime[μs]</td><td>i64</td></tr></thead><tbody><tr><td>&quot;BRONX&quot;</td><td>2021-02-26 00:00:00</td><td>0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-06 00:00:00</td><td>0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-08 00:00:00</td><td>0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-10 00:00:00</td><td>4</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-11 00:00:00</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────┬─────────────────────┬───────────────────────────┐\n",
       "│ borough ┆ day                 ┆ number_of_persons_injured │\n",
       "│ ---     ┆ ---                 ┆ ---                       │\n",
       "│ str     ┆ datetime[μs]        ┆ i64                       │\n",
       "╞═════════╪═════════════════════╪═══════════════════════════╡\n",
       "│ BRONX   ┆ 2021-02-26 00:00:00 ┆ 0                         │\n",
       "│ BRONX   ┆ 2021-04-06 00:00:00 ┆ 0                         │\n",
       "│ BRONX   ┆ 2021-04-08 00:00:00 ┆ 0                         │\n",
       "│ BRONX   ┆ 2021-04-10 00:00:00 ┆ 4                         │\n",
       "│ BRONX   ┆ 2021-04-11 00:00:00 ┆ 0                         │\n",
       "└─────────┴─────────────────────┴───────────────────────────┘"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df = ctx.execute(\"\"\"\n",
    "    SELECT\n",
    "        borough,\n",
    "        crash_date AS day,\n",
    "        SUM(number_of_persons_injured)\n",
    "    FROM \n",
    "        crashes\n",
    "    WHERE \n",
    "        borough IS NOT NULL\n",
    "    GROUP BY \n",
    "        borough, crash_date\n",
    "    ORDER BY \n",
    "        borough, day\n",
    "\"\"\")\n",
    "\n",
    "daily_df.collect().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde53df-16a9-4ce6-a6c9-52552b2b88fa",
   "metadata": {},
   "source": [
    "Notice I had to use `collect()` function to get the results thats because by default the SQL uses lazy execution.\n",
    "You can see this since printing the dataframe actually prints the query plan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6709aecb-5ea3-4042-b02f-35a76f89ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)\n",
      "\n",
      "SORT BY [col(\"borough\"), col(\"day\")]\n",
      "   SELECT [col(\"borough\"), col(\"crash_date\").alias(\"day\"), col(\"number_of_persons_injured\")] FROM\n",
      "    AGGREGATE\n",
      "    \t[col(\"number_of_persons_injured\").sum()] BY [col(\"borough\"), col(\"crash_date\")] FROM\n",
      "      FILTER col(\"borough\").is_not_null() FROM\n",
      "      DF [\"crash_date\", \"crash_time\", \"borough\", \"zip_code\"]; PROJECT */30 COLUMNS; SELECTION: \"None\"\n"
     ]
    }
   ],
   "source": [
    "print(daily_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d44e052-3855-406f-b7f8-139708c0c665",
   "metadata": {},
   "source": [
    "To get back a Polars dataframe I would have to use the `eager=True` paramater in the execute method.\n",
    "\n",
    "Now I can register this new dataframe as a table called `daily_crashes` in the SQLContext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fab83d06-5f21-4ac1-81ad-0a09cd6a3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = ctx.register(\"daily_crashes\", daily_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbe6a5-442e-4dff-b58a-1165c4c03eb8",
   "metadata": {},
   "source": [
    "I can see the tables in the context using the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eae2c969-1e49-4dae-a409-486f513885c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crashes', 'daily_crashes']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571026f5-266f-4516-a0a0-829fa068a9be",
   "metadata": {},
   "source": [
    "Now say I want to get the current day's number of injuried people and the prior days; I could use the lag function in SQL to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "461358da-6a28-4799-a722-d2ade734ea5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidOperationError",
     "evalue": "unsupported SQL function: lag",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidOperationError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m    SELECT\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m        borough,\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m        day,\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m        number_of_persons_injured,\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m        LAG(1,number_of_persons_injured) \u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m            OVER (\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m            PARTITION BY borough \u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43m            ORDER BY day ASC\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m            ) AS prior_day_injured\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43mFROM\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;43m    daily_crashes\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43mORDER BY \u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43m    borough,\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43m    day DESC\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/polars/sql/context.py:282\u001b[0m, in \u001b[0;36mSQLContext.execute\u001b[0;34m(self, query, eager)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, eager: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LazyFrame \u001b[38;5;241m|\u001b[39m DataFrame:\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    Parse the given SQL query and execute it against the registered frame data.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    └────────┴─────────────┴─────────┘\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m     res \u001b[38;5;241m=\u001b[39m wrap_ldf(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctxt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mcollect() \u001b[38;5;28;01mif\u001b[39;00m (eager \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eager_execution) \u001b[38;5;28;01melse\u001b[39;00m res\n",
      "\u001b[0;31mInvalidOperationError\u001b[0m: unsupported SQL function: lag"
     ]
    }
   ],
   "source": [
    "ctx.execute(\"\"\"\n",
    "    SELECT\n",
    "        borough,\n",
    "        day,\n",
    "        number_of_persons_injured,\n",
    "        LAG(1,number_of_persons_injured) \n",
    "            OVER (\n",
    "            PARTITION BY borough \n",
    "            ORDER BY day ASC\n",
    "            ) AS prior_day_injured\n",
    "FROM\n",
    "    daily_crashes\n",
    "ORDER BY \n",
    "    borough,\n",
    "    day DESC\n",
    "\"\"\", eager=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26ab2a-6035-44fb-b3a2-0563ee5b491c",
   "metadata": {},
   "source": [
    "I finally hit snag in Polars: their doesnt seem to be a lot of support for Window functions. This was dissapointing since the library was so promising!  \n",
    "\n",
    "Luckily there is another library that support blazingly fast SQL queries and integrates with Polars (and Pandas) directly: DuckDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5307c3-e2f6-4b87-a140-5aa1a50a9878",
   "metadata": {},
   "source": [
    "## DuckDB To The Rescue For SQL <a class=\"anchor\" id=\"fourth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d84eaf-cbcc-4564-a7e7-3761d0d99a43",
   "metadata": {},
   "source": [
    "I heard about [DuckDB](https://duckdb.org/) when I saw someone star it on github and thought it was \"Yet Another SQL Engine\". While DuckDB is a SQL engine it is much more! First, it's parallel query processing library written in C++. From the website it's,\n",
    "\n",
    "        DuckDB is designed to support analytical query workloads, also known as Online analytical processing (OLAP). These workloads are characterized by complex, relatively long-running queries that process significant portions of the stored dataset, for example aggregations over entire tables or joins between several large tables.\n",
    "        ...\n",
    "        DuckDB contains a columnar-vectorized query execution engine, where queries are still interpreted, but a large batch of values (a “vector”) are processed in one operation.\n",
    "\n",
    "In other words, DuckDB is can be used for fast query execution across large datasets. Duc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b72d3d8-f580-40b9-8922-1252f1414582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "query = duckdb.sql(\"\"\"\n",
    "    SELECT\n",
    "        borough,\n",
    "        day,\n",
    "        number_of_persons_injured,\n",
    "        LAG(1, number_of_persons_injured) \n",
    "            OVER (\n",
    "                PARTITION BY borough \n",
    "                ORDER BY day ASC\n",
    "                ) as prior_day_injured\n",
    "FROM\n",
    "    daily_df\n",
    "ORDER BY \n",
    "    borough,\n",
    "    day DESC\n",
    "LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e0b63-9a3f-4db3-b013-d2184776fa6d",
   "metadata": {},
   "source": [
    "Now we can see the output of the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "626b0f64-8589-4607-ac43-43008ecdf6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────┬─────────────────────┬───────────────────────────┬───────────────────┐\n",
       "│ borough │         day         │ number_of_persons_injured │ prior_day_injured │\n",
       "│ varchar │      timestamp      │           int64           │       int32       │\n",
       "├─────────┼─────────────────────┼───────────────────────────┼───────────────────┤\n",
       "│ BRONX   │ 2022-04-24 00:00:00 │                         0 │                 1 │\n",
       "│ BRONX   │ 2022-03-26 00:00:00 │                         7 │                 1 │\n",
       "│ BRONX   │ 2022-03-25 00:00:00 │                         1 │                 1 │\n",
       "│ BRONX   │ 2022-03-24 00:00:00 │                         1 │                 1 │\n",
       "│ BRONX   │ 2022-03-22 00:00:00 │                         1 │                 1 │\n",
       "└─────────┴─────────────────────┴───────────────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c7284e-1d7e-4538-b2de-40b222498820",
   "metadata": {},
   "source": [
    "Then we can return the result as polars dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d2e41c8-65b9-4e3e-bb5b-c4b6cb902a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>borough</th><th>day</th><th>number_of_persons_injured</th><th>prior_day_injured</th></tr><tr><td>str</td><td>datetime[μs]</td><td>i64</td><td>i32</td></tr></thead><tbody><tr><td>&quot;BRONX&quot;</td><td>2022-04-24 00:00:00</td><td>0</td><td>1</td></tr><tr><td>&quot;BRONX&quot;</td><td>2022-03-26 00:00:00</td><td>7</td><td>1</td></tr><tr><td>&quot;BRONX&quot;</td><td>2022-03-25 00:00:00</td><td>1</td><td>1</td></tr><tr><td>&quot;BRONX&quot;</td><td>2022-03-24 00:00:00</td><td>1</td><td>1</td></tr><tr><td>&quot;BRONX&quot;</td><td>2022-03-22 00:00:00</td><td>1</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────┬─────────────────────┬───────────────────────────┬───────────────────┐\n",
       "│ borough ┆ day                 ┆ number_of_persons_injured ┆ prior_day_injured │\n",
       "│ ---     ┆ ---                 ┆ ---                       ┆ ---               │\n",
       "│ str     ┆ datetime[μs]        ┆ i64                       ┆ i32               │\n",
       "╞═════════╪═════════════════════╪═══════════════════════════╪═══════════════════╡\n",
       "│ BRONX   ┆ 2022-04-24 00:00:00 ┆ 0                         ┆ 1                 │\n",
       "│ BRONX   ┆ 2022-03-26 00:00:00 ┆ 7                         ┆ 1                 │\n",
       "│ BRONX   ┆ 2022-03-25 00:00:00 ┆ 1                         ┆ 1                 │\n",
       "│ BRONX   ┆ 2022-03-24 00:00:00 ┆ 1                         ┆ 1                 │\n",
       "│ BRONX   ┆ 2022-03-22 00:00:00 ┆ 1                         ┆ 1                 │\n",
       "└─────────┴─────────────────────┴───────────────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_prior_df = query.pl()\n",
    "day_prior_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f5c1c9-0a5e-486b-aaa6-cd082ad331f3",
   "metadata": {},
   "source": [
    "Now we can see another cool part of DuckDB, you can execute SQL directly on local files!\n",
    "\n",
    "First we save the daily crash dataframe as parquet filea and remember its a lazy dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd8deafd-a6b6-4047-ab55-5dba4039794a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>naive plan: (run <b>LazyFrame.explain(optimized=True)</b> to see the optimized plan)</i>\n",
       "    <p></p>\n",
       "    <div>SORT BY [col(\"borough\"), col(\"day\")]<p></p>   SELECT [col(\"borough\"), col(\"crash_date\").alias(\"day\"), col(\"number_of_persons_injured\")] FROM<p></p>    AGGREGATE<p></p>    \t[col(\"number_of_persons_injured\").sum()] BY [col(\"borough\"), col(\"crash_date\")] FROM<p></p>      FILTER col(\"borough\").is_not_null() FROM<p></p>      DF [\"crash_date\", \"crash_time\", \"borough\", \"zip_code\"]; PROJECT */30 COLUMNS; SELECTION: \"None\"</div>"
      ],
      "text/plain": [
       "<LazyFrame [3 cols, {\"borough\": Utf8 … \"number_of_persons_injured\": Int64}] at 0x7F1D68977040>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7196fb2-9268-489b-910e-0dc1c6408cb0",
   "metadata": {},
   "source": [
    "It turns out you cant write lazy dataframes as parquet. So first we'll collect it and then write it to parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c5309bf-1365-4825-afa5-061c543cdba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.collect().write_parquet(\"daily_crashes.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1daeae5-cd40-4c7c-aaaf-d373da92e832",
   "metadata": {},
   "source": [
    "[Apache Parquet](https://parquet.apache.org/) is a compressed columnar-stored format file type that is create for analytical queries. Column-based formats are particuarly good for OLAP queries since entire columns can be read in continuous and have aggregrations performed on them. The datatypes for each column are known allowing for compression. Since the columns and datatypes are known we can read them in with the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49159545-2a8f-463e-9242-34caeb906e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>file_name</th><th>name</th><th>type</th><th>type_length</th><th>repetition_type</th><th>num_children</th><th>converted_type</th><th>scale</th><th>precision</th><th>field_id</th><th>logical_type</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;daily_crashes.…</td><td>&quot;root&quot;</td><td>null</td><td>null</td><td>null</td><td>3</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;daily_crashes.…</td><td>&quot;borough&quot;</td><td>&quot;BYTE_ARRAY&quot;</td><td>null</td><td>&quot;OPTIONAL&quot;</td><td>null</td><td>&quot;UTF8&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;StringType()&quot;</td></tr><tr><td>&quot;daily_crashes.…</td><td>&quot;day&quot;</td><td>&quot;INT64&quot;</td><td>null</td><td>&quot;OPTIONAL&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;TimestampType(…</td></tr><tr><td>&quot;daily_crashes.…</td><td>&quot;number_of_pers…</td><td>&quot;INT64&quot;</td><td>null</td><td>&quot;OPTIONAL&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 11)\n",
       "┌────────────┬────────────┬────────────┬────────────┬───┬───────┬───────────┬──────────┬───────────┐\n",
       "│ file_name  ┆ name       ┆ type       ┆ type_lengt ┆ … ┆ scale ┆ precision ┆ field_id ┆ logical_t │\n",
       "│ ---        ┆ ---        ┆ ---        ┆ h          ┆   ┆ ---   ┆ ---       ┆ ---      ┆ ype       │\n",
       "│ str        ┆ str        ┆ str        ┆ ---        ┆   ┆ i64   ┆ i64       ┆ i64      ┆ ---       │\n",
       "│            ┆            ┆            ┆ str        ┆   ┆       ┆           ┆          ┆ str       │\n",
       "╞════════════╪════════════╪════════════╪════════════╪═══╪═══════╪═══════════╪══════════╪═══════════╡\n",
       "│ daily_cras ┆ root       ┆ null       ┆ null       ┆ … ┆ null  ┆ null      ┆ null     ┆ null      │\n",
       "│ hes.parque ┆            ┆            ┆            ┆   ┆       ┆           ┆          ┆           │\n",
       "│ t          ┆            ┆            ┆            ┆   ┆       ┆           ┆          ┆           │\n",
       "│ daily_cras ┆ borough    ┆ BYTE_ARRAY ┆ null       ┆ … ┆ null  ┆ null      ┆ null     ┆ StringTyp │\n",
       "│ hes.parque ┆            ┆            ┆            ┆   ┆       ┆           ┆          ┆ e()       │\n",
       "│ t          ┆            ┆            ┆            ┆   ┆       ┆           ┆          ┆           │\n",
       "│ daily_cras ┆ day        ┆ INT64      ┆ null       ┆ … ┆ null  ┆ null      ┆ null     ┆ Timestamp │\n",
       "│ hes.parque ┆            ┆            ┆            ┆   ┆       ┆           ┆          ┆ Type(isAd │\n",
       "│ t          ┆            ┆            ┆            ┆   ┆       ┆           ┆          ┆ justedToU │\n",
       "│            ┆            ┆            ┆            ┆   ┆       ┆           ┆          ┆ TC=0,…    │\n",
       "│ daily_cras ┆ number_of_ ┆ INT64      ┆ null       ┆ … ┆ null  ┆ null      ┆ null     ┆ null      │\n",
       "│ hes.parque ┆ persons_in ┆            ┆            ┆   ┆       ┆           ┆          ┆           │\n",
       "│ t          ┆ jured      ┆            ┆            ┆   ┆       ┆           ┆          ┆           │\n",
       "└────────────┴────────────┴────────────┴────────────┴───┴───────┴───────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\"SELECT * FROM parquet_schema(daily_crashes.parquet)\").pl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb11776a-9999-4cba-81ab-1ad47a03262f",
   "metadata": {},
   "source": [
    "Then we can perform queries on the actualy files without having to resort to dataframes at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c016a097-4ca5-42d7-a36c-e13c1efcb8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = duckdb.sql(\"\"\"\n",
    "    SELECT\n",
    "        borough,\n",
    "        day,\n",
    "        number_of_persons_injured,\n",
    "        SUM(number_of_persons_injured) \n",
    "            OVER (\n",
    "                PARTITION BY borough \n",
    "                ORDER BY day ASC\n",
    "                ) AS cumulative_injuried\n",
    "    FROM \n",
    "        read_parquet(daily_crashes.parquet)\n",
    "    ORDER BY\n",
    "        borough,\n",
    "        day ASC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d39cc91f-81a2-431e-b3be-5a2bf26b1094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>borough</th><th>day</th><th>number_of_persons_injured</th><th>cumulative_injuried</th></tr><tr><td>str</td><td>datetime[μs]</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;BRONX&quot;</td><td>2021-02-26 00:00:00</td><td>0</td><td>0.0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-06 00:00:00</td><td>0</td><td>0.0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-08 00:00:00</td><td>0</td><td>0.0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-10 00:00:00</td><td>4</td><td>4.0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-11 00:00:00</td><td>0</td><td>4.0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-12 00:00:00</td><td>0</td><td>4.0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-13 00:00:00</td><td>3</td><td>7.0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-14 00:00:00</td><td>3</td><td>10.0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-15 00:00:00</td><td>4</td><td>14.0</td></tr><tr><td>&quot;BRONX&quot;</td><td>2021-04-16 00:00:00</td><td>6</td><td>20.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌─────────┬─────────────────────┬───────────────────────────┬─────────────────────┐\n",
       "│ borough ┆ day                 ┆ number_of_persons_injured ┆ cumulative_injuried │\n",
       "│ ---     ┆ ---                 ┆ ---                       ┆ ---                 │\n",
       "│ str     ┆ datetime[μs]        ┆ i64                       ┆ f64                 │\n",
       "╞═════════╪═════════════════════╪═══════════════════════════╪═════════════════════╡\n",
       "│ BRONX   ┆ 2021-02-26 00:00:00 ┆ 0                         ┆ 0.0                 │\n",
       "│ BRONX   ┆ 2021-04-06 00:00:00 ┆ 0                         ┆ 0.0                 │\n",
       "│ BRONX   ┆ 2021-04-08 00:00:00 ┆ 0                         ┆ 0.0                 │\n",
       "│ BRONX   ┆ 2021-04-10 00:00:00 ┆ 4                         ┆ 4.0                 │\n",
       "│ …       ┆ …                   ┆ …                         ┆ …                   │\n",
       "│ BRONX   ┆ 2021-04-13 00:00:00 ┆ 3                         ┆ 7.0                 │\n",
       "│ BRONX   ┆ 2021-04-14 00:00:00 ┆ 3                         ┆ 10.0                │\n",
       "│ BRONX   ┆ 2021-04-15 00:00:00 ┆ 4                         ┆ 14.0                │\n",
       "│ BRONX   ┆ 2021-04-16 00:00:00 ┆ 6                         ┆ 20.0                │\n",
       "└─────────┴─────────────────────┴───────────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.pl().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e247d5-ace6-4c90-927e-97e9090a864b",
   "metadata": {},
   "source": [
    "Pretty cool!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60192db-4916-4c22-b3bd-f8322c41ca9e",
   "metadata": {},
   "source": [
    "## Conclusions <a class=\"anchor\" id=\"fifth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40edceb7-1d3d-4975-820f-67087937ef31",
   "metadata": {},
   "source": [
    "In this post I quickly covered what I view as the limitations in Pandas library. Next I covered how to get set up in with \n",
    "Juptyer lab using [Docker](https://www.docker.com/) on [AWS](https://aws.amazon.com/) and covered some basics of [Polars](https://www.pola.rs/), [DuckDB](https://duckdb.org/) and how to use the two in combination. The benefits of Polars is that,\n",
    "\n",
    "* It allows for fast parallel querying on dataframes.\n",
    "* It uses Apache Arrow for backend datatypes making it efficient for memory.\n",
    "* It has both lazy and eager execution mode.\n",
    "* It allows for SQL queries direcly on dataframes.\n",
    "* Its API is similar to Spark's API and allows for highly readable queries using method chaining.\n",
    "\n",
    "I am still new to both libraries, but looking forward to learning them more.\n",
    "\n",
    "Hope you enjoyed reading this!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
